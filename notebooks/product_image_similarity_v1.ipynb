{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# standard lib:\n",
    "import heapq\n",
    "import pathlib\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# ML/data science libraries:\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "import pandas as pd\n",
    "\n",
    "# TenserFlow/Keras classes:\n",
    "from tensorflow.keras.applications import ResNet50V2\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import GlobalMaxPool2D\n",
    "\n",
    "# plotting and imaging:\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load and Process Images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# n.b. we don't need to sort since we're not training the model:\n",
    "def get_file_paths():\n",
    "    \"\"\" Create generator of all image file paths.\n",
    "\n",
    "    :return {generator}\n",
    "    \"\"\"\n",
    "\n",
    "    # We could also have used `pathlib.Path().glob()`, but that returns a POSIX path rather than str:\n",
    "    return glob.iglob('../data/e-commerce-product-images/**/*.jpg', recursive=True)\n",
    "\n",
    "file_paths = get_file_paths()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Explore Data -- i.e. images:\n",
    "N.b. the dataset includes different size images and images with different number of channels (i.e. both RGB and grayscale) images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "example_img = cv2.imread(next(file_paths))\n",
    "print(plt.imshow(example_img))\n",
    "\n",
    "# reset generator:\n",
    "file_paths = get_file_paths()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load ResNet Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# constants:\n",
    "IMG_HEIGHT  = 224\n",
    "IMG_WIDTH   = 224\n",
    "\n",
    "resnet_model = ResNet50V2(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)\n",
    ")\n",
    "resnet_model.trainable = False\n",
    "\n",
    "resnet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Update the model by adding a global max pooling layer:\n",
    "# In essence, we replaced the last couple layers of the original ResNet model with a layer that outputs the embedding/features of the image.\n",
    "# Recall that global pooling always reduces the output to be shape 1 x 1 x channels; essentially, outputting a layer of feature-maps.\n",
    "model = Sequential([\n",
    "    resnet_model,\n",
    "    GlobalMaxPool2D()\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Aside:** if we didn't specify `include_top=False` in `resnet_model` from the previous two cells,\n",
    "we could alternatively have created a new model and get the last 3rd to last layer:\n",
    "```\n",
    "resnet_model_ = ResNet50V2(weights='imagenet')\n",
    "```\n",
    "\n",
    "This would, however, result in the exact same model:\n",
    "```\n",
    "feature_extraction_model = Model(\n",
    "    name='ResNet50V2_ExtractFeature',\n",
    "    inputs=resnet_model_.inputs,\n",
    "    outputs=resnet_model_.get_layer('post_relu').output\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Helper methods:\n",
    "\n",
    "def cosine_similarity(embedding_1:np.ndarray, embedding_2:np.ndarray):\n",
    "    \"\"\" Calculates the cosine similarity of two vectors.\n",
    "\n",
    "    :param embedding_1: An embedding vector.\n",
    "    :param embedding_2: An embedding vector.\n",
    "    :return: A single number (numpy float) -- the cosine similarity value.\n",
    "    \"\"\"\n",
    "\n",
    "    # `distance.cosine` computes distance, not similarity; subtract by 1 to get similarity:\n",
    "    return 1 - spatial.distance.cosine(embedding_1, embedding_2)\n",
    "\n",
    "def process_image(img:np.ndarray):\n",
    "    \"\"\" Pre-process images before feeding to model.\n",
    "\n",
    "    Resizes image, scales (/255), and expands array dimension. The model requires specific input dimensions (shape),\n",
    "    therefore resizing and adding dimension is necessary. Scaling improves performance.\n",
    "    TODO: ideally, we should use standard deviation and mean of dataset instead of simply dividing by 255.\n",
    "\n",
    "    :param img:\n",
    "    :return {np.ndarray}: returns processed image\n",
    "    \"\"\"\n",
    "    # see comparison of different interpolation methods: <https://chadrick-kwag.net/cv2-resize-interpolation-methods/>\n",
    "    processed_img = cv2.resize(img, (IMG_HEIGHT, IMG_WIDTH), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    # We can use TF's ResNet `preprocess_input` <https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet_v2/preprocess_input>\n",
    "    # however, because the datasets are quite different, it might do more harm than good <https://stackoverflow.com/a/58250681>;\n",
    "    # we can therefore, simply divide by 255:\n",
    "    processed_img = processed_img / 255\n",
    "\n",
    "    # ResNet model expects input shape (batch_size, img_height, img_width, channels) -- we need to add batch_size dimension:\n",
    "    processed_img = np.expand_dims(processed_img, axis=0)\n",
    "    return processed_img\n",
    "\n",
    "def get_embedding(file_path:str):\n",
    "    img = cv2.imread(file_path)\n",
    "    img = process_image(img)\n",
    "    embedding = model.predict(img)\n",
    "\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Calculate the Embedding Vector and Cosine Similarity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df_embeddings = pd.DataFrame(columns=['file', 'file_path', 'embedding'])\n",
    "\n",
    "# TODO: can we optimize/speed-up this, perhaps via batch processing?\n",
    "for file_path_ in file_paths:\n",
    "    embedding_ = get_embedding(file_path_)\n",
    "    file_name_ = file_path_.split('/')[-1]\n",
    "\n",
    "    df_embeddings = df_embeddings.append({'file': file_name_, 'file_path': file_path_, 'embedding': embedding_}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# write out to file:\n",
    "df_embeddings.to_csv(pathlib.Path('../data/output/embedding.csv'))\n",
    "\n",
    "df_embeddings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "n_images = len(df_embeddings)\n",
    "similarity_scores = np.zeros((n_images, n_images))\n",
    "for i in range(n_images):\n",
    "    for j in range(n_images):\n",
    "        similarity_scores[i, j] = cosine_similarity(df_embeddings.iloc[i]['embedding'], df_embeddings.iloc[j]['embedding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# create empty dataframe with file names as both the column and index names:\n",
    "file_names = df_embeddings.loc[:, 'file'].tolist()\n",
    "df_similarity = pd.DataFrame(similarity_scores, columns=file_names, index=file_names)\n",
    "\n",
    "# write out to file:\n",
    "df_similarity.to_csv(pathlib.Path('../data/output/similarity_scores.csv'))\n",
    "\n",
    "df_similarity.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Find Similar Images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def find_most_similar_images(img_path:str, num_results:int=5):\n",
    "    # Load single image, process, and get embedding:\n",
    "    target_embedding = get_embedding(img_path)\n",
    "\n",
    "    # Find max embedding:\n",
    "    top_matches = []\n",
    "    for db_img_file_path, db_img_embedding in zip(df_embeddings['file_path'], df_embeddings['embedding']):\n",
    "        # top_matches needs to exclude the target image itself from being returned:\n",
    "        if os.path.samefile(db_img_file_path, img_path):\n",
    "            continue\n",
    "\n",
    "        similarity_score = cosine_similarity(target_embedding, db_img_embedding)\n",
    "\n",
    "        # We use `heapq` and keep only N number of elements -- this prevents us from holding the entire dataset in memory:\n",
    "        # Ensure heap has N number of elements (this is done by adding the first N items):\n",
    "        if len(top_matches) < num_results:\n",
    "            heapq.heappush(top_matches, (similarity_score, db_img_file_path))\n",
    "        # After creating an N-element heap, if a new item has a LARGER value than the SMALLEST in the heap,\n",
    "        # then replace the smallest with the new item:\n",
    "        # `heapq.nsmallest` returns a list, each element in list is a tuple (similarity, file_path); hence the reason for the double subscript `[0][0]`:\n",
    "        elif similarity_score > heapq.nsmallest(1, top_matches)[0][0]:\n",
    "            heapq.heapreplace(top_matches, (similarity_score, db_img_file_path))\n",
    "\n",
    "    return top_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def display_similar_images(img_path:str, num_results:int=5):\n",
    "    top_results = find_most_similar_images(img_path, num_results)\n",
    "\n",
    "    # display multiple images; see <https://stackoverflow.com/q/19471814>:\n",
    "    for similarity_score, file_path in top_results: # recall `top_results` returns a tuple of (similarity, file_path)\n",
    "        img = cv2.imread(file_path)\n",
    "        plt.figure()\n",
    "        plt.title(file_path.split('/')[-1]) # use file name as figure title\n",
    "        plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "example_img_path = '../data/e-commerce-product-images/Footwear/Men/Images/images_with_product_ids/2089.jpg'\n",
    "\n",
    "print('----- Selected Image: -----')\n",
    "plt.imshow(cv2.imread(example_img_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('----- Similar Images: -----')\n",
    "display_similar_images(example_img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}